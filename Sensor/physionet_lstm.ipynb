{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Time', 'L1' , 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', \n",
    "            'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', \n",
    "            'Total_Force_Left', 'Total_Force_Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    "\n",
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_category(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = np.dstack(loaded)\n",
    "\treturn loaded\n",
    "\n",
    "\n",
    "# load a dataset category, such as train or test\n",
    "def load_dataset_category(category, prefix=''):\n",
    "\t# load all 19 files as a single array\n",
    "\tfilenames = []\n",
    "\tfor fname in features:\n",
    "\t\tfilenames.append(category + '/' + fname + '_' + category + '.txt')\n",
    "\n",
    "\tX = load_category(filenames, prefix)\n",
    "\ty = load_file(prefix + 'y_'+ category +'.txt')\n",
    "\thy = load_file(prefix + 'hyscore_'+ category +'.txt')\n",
    "\treturn X, y, hy\n",
    "\n",
    "# returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\ttrainX, trainy, trainHY = load_dataset_category('train', prefix)\n",
    "\tprint(trainX.shape, trainy.shape, trainHY.shape)\n",
    "\ttestX, testy, testHY = load_dataset_category('test', prefix)\n",
    "\tprint(testX.shape, testy.shape, testHY.shape)\n",
    " \n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode\n",
    "\ttrainy = tf.keras.utils.to_categorical(trainy)\n",
    "\ttrainHY = tf.keras.utils.to_categorical(trainHY)\n",
    "\ttesty = tf.keras.utils.to_categorical(testy)\n",
    "\ttestHY = tf.keras.utils.to_categorical(testHY)  \n",
    " \n",
    "\treturn trainX, trainy, trainHY, testX, testy, testHY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30104, 100, 19) (30104, 1) (30104, 1)\n",
      "(13761, 100, 19) (13761, 1) (13761, 1)\n",
      "Training Data =  (30104, 100, 19)\n",
      "Training Class =  (30104, 2)\n",
      "Training HoehnYahr Class =  (30104, 4)\n",
      "Test Data =  (13761, 100, 19)\n",
      "Test Class =  (13761, 2)\n",
      "Test HoehnYahr Class =  (13761, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, trainHY, testX, testy, testHY = load_dataset('Final/')\n",
    "print(\"Training Data = \", trainX.shape)\n",
    "print(\"Training Class = \", trainy.shape)\n",
    "print(\"Training HoehnYahr Class = \", trainHY.shape)\n",
    "print(\"Test Data = \", testX.shape)\n",
    "print(\"Test Class = \", testy.shape)\n",
    "print(\"Test HoehnYahr Class = \", testHY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_data, output_size, neurons, activ_func='linear',\n",
    "                     dropout=0.2, loss='mse', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model\n",
    "np.random.seed(245)\n",
    "window_len = 5\n",
    "test_size = 0.2\n",
    "zero_base = True\n",
    "lstm_neurons = 50\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "loss = 'mse'\n",
    "dropout = 0.24\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                14000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,051\n",
      "Trainable params: 14,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_lstm_model(\n",
    "    trainX, output_size=1, neurons=lstm_neurons, dropout=dropout, loss=loss,\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "941/941 [==============================] - 49s 49ms/step - loss: 0.3026 - val_loss: 0.2510\n",
      "Epoch 2/20\n",
      "941/941 [==============================] - 46s 48ms/step - loss: 0.2532 - val_loss: 0.2502\n",
      "Epoch 3/20\n",
      "941/941 [==============================] - 44s 46ms/step - loss: 0.2508 - val_loss: 0.2501\n",
      "Epoch 4/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2501 - val_loss: 0.2500\n",
      "Epoch 5/20\n",
      "941/941 [==============================] - 44s 47ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 6/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 7/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 8/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 9/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 10/20\n",
      "941/941 [==============================] - 44s 47ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 11/20\n",
      "941/941 [==============================] - 45s 47ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 12/20\n",
      "941/941 [==============================] - 44s 47ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 13/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 14/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 15/20\n",
      "941/941 [==============================] - 45s 48ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 16/20\n",
      "941/941 [==============================] - 46s 49ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 17/20\n",
      "941/941 [==============================] - 45s 47ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 18/20\n",
      "941/941 [==============================] - 46s 49ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 19/20\n",
      "941/941 [==============================] - 65s 69ms/step - loss: 0.2500 - val_loss: 0.2500\n",
      "Epoch 20/20\n",
      "941/941 [==============================] - 56s 59ms/step - loss: 0.2500 - val_loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "phy_history = model.fit(trainX,\n",
    "                        trainy,\n",
    "                        validation_data=(testX, testy),\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        verbose = 1,\n",
    "                        shuffle=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, target, testX, testy):\n",
    "  y_pred = model.predict(testX)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "  y_test = np.argmax(testy, axis=1)\n",
    "\n",
    "  cm = tf.math.confusion_matrix(labels = y_test, predictions = y_pred)\n",
    "  # Calculate accuracy\n",
    "  cm_np = cm.numpy()\n",
    "  conf_acc = (cm_np[0, 0] + cm_np[1, 1])/ np.sum(cm_np) * 100\n",
    "  print(\"Accuracy for Test Data = \", conf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test Data =  66.07077973984448\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(model, [0,1], testX, testy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bc555d4404cb76c05abf652b46a3ff7311252ed528c07b449819f2d141a7c7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
